{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# milliPillar Pillar Trace Analysis\n",
    "\n",
    "## Version 3.1\n",
    "\n",
    "## Last Updated: 10/24/2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:01:40.686500Z",
     "start_time": "2021-08-18T20:01:39.901179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cb\n",
    "import matplotlib.image \n",
    "import matplotlib.patches\n",
    "import matplotlib.backends.backend_pdf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from pathlib import Path  \n",
    "import warnings\n",
    "from pandas import ExcelWriter\n",
    "import ipykernel\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:01:40.701908Z",
     "start_time": "2021-08-18T20:01:40.687887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select Data to Analyze \n",
    "main_folder = ''\n",
    "\n",
    "# Set Frame Rate in FPS\n",
    "frame_rate = 20\n",
    "\n",
    "# Set Pixel to Micron Conversion Factor\n",
    "microns_per_pixel = 6.5\n",
    "\n",
    "# Set the Unloaded Distance Between the Pillar Heads (in microns)\n",
    "unloaded_distance = 3000\n",
    "\n",
    "# Set Elastic Coefficient in uN/um\n",
    "coefficient = 2.1 \n",
    "\n",
    "# Can change this to select from a pop up window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:01:40.717076Z",
     "start_time": "2021-08-18T20:01:40.702909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Regimen Excel File\n",
    "regimen_file = ''\n",
    "regimen = pd.read_excel(regimen_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:01:40.733100Z",
     "start_time": "2021-08-18T20:01:40.718078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Makes sure all CSV files are in the proper configuration \n",
    "\n",
    "# Create a List of .csv Files\n",
    "csv_list = glob.glob(main_folder + \"*.csv\")\n",
    "csv_names = []\n",
    "for x in csv_list: \n",
    "    csv_names.append(os.path.splitext(os.path.basename(x))[0])\n",
    "    \n",
    "csv_left = glob.glob(main_folder + \"*_left.csv\")\n",
    "csv_left_names = []\n",
    "for x in csv_left: \n",
    "    csv_left_names.append(os.path.splitext(os.path.basename(x))[0])\n",
    "    \n",
    "csv_right = glob.glob(main_folder + \"*_right.csv\")\n",
    "csv_right_names = []\n",
    "for x in csv_right: \n",
    "    csv_right_names.append(os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "# Create a list of .csv files in the correct format \n",
    "with_left = []\n",
    "for x in csv_left_names: \n",
    "    with_left.append(os.path.basename(x).replace(\"_left\", \"\"))\n",
    "with_right = []\n",
    "for x in csv_right_names: \n",
    "    with_right.append(os.path.basename(x).replace(\"_right\", \"\"))\n",
    "\n",
    "correct_csv = list(set.intersection(set(with_left), set(with_right)))\n",
    "\n",
    "# Corrects remaining .csv files and adds them to the list \n",
    "to_process = list((set(csv_names) - set(csv_right_names)) - set(csv_left_names))\n",
    "\n",
    "for x in to_process: \n",
    "    data = data = pd.read_csv(os.path.join(main_folder, x + '.csv'))\n",
    "\n",
    "    left_x = data.loc[:, 'Left X']\n",
    "    left_y = data.loc[:, 'Left Y']\n",
    "    right_x = data.loc[:, 'Right X']\n",
    "    right_y = data.loc[:, 'Right Y'] \n",
    "\n",
    "    left = {'X' : left_x, 'Y': left_y}\n",
    "    left_df = pd.DataFrame(data=left)\n",
    "    right = {'X' : right_x, 'Y' : right_y}\n",
    "    right_df = pd.DataFrame(data=right) \n",
    "\n",
    "    left_name = os.path.join(main_folder, x + \"_left.csv\")\n",
    "    right_name = os.path.join(main_folder, x + \"_right.csv\")\n",
    "\n",
    "    left_df.to_csv(left_name)\n",
    "    right_df.to_csv(right_name)\n",
    "\n",
    "    correct_csv.append(x)\n",
    "\n",
    "# Makes list unique and sort\n",
    "correct_csv = list(set(correct_csv))\n",
    "correct_csv.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tissue Widths and Calculate XC Areas\n",
    "# Note: Width Input File Should be in Pixels \n",
    "width_file = os.path.join(main_folder, 'Widths', \"TissueWidths.csv\")\n",
    "widths = pd.read_csv(width_file)\n",
    "width_microns = widths['Width'] * microns_per_pixel\n",
    "widths['Width (um)'] = width_microns \n",
    "widths['Width (mm)'] = width_microns / 1000 \n",
    "areas = (np.square(((widths['Width (mm)'])/2))) * np.pi\n",
    "widths['Area (mm2)'] = areas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:01:40.765131Z",
     "start_time": "2021-08-18T20:01:40.750128Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_trace(current_tissue):\n",
    "\n",
    "    # Display Tissue Name\n",
    "    print(\"Processing Tissue {}\".format(current_tissue))\n",
    "\n",
    "    # Load Tissue Trace\n",
    "    left_file = os.path.join(main_folder, current_tissue + \"_left.csv\")\n",
    "    right_file = os.path.join(main_folder, current_tissue + \"_right.csv\")\n",
    "    left_data = pd.read_csv(left_file)\n",
    "    right_data = pd.read_csv(right_file) \n",
    "\n",
    "    # Create New Dataframe \n",
    "    left_x = left_data.loc[:, 'X']\n",
    "    left_y = left_data.loc[:, 'Y']\n",
    "    right_x = right_data.loc[:, 'X']\n",
    "    right_y = right_data.loc[:, 'Y'] \n",
    "    data = {'Left X':left_x, 'Left Y':left_y, 'Right X':right_x, 'Right Y':right_y}\n",
    "    data = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "    # Add Time Column to DF\n",
    "    time = np.arange(0,(data.shape[0])/frame_rate,(1/frame_rate))\n",
    "    data['Time'] = time\n",
    "\n",
    "    #Add distance to DF\n",
    "    x_diff =  right_x - left_x\n",
    "    y_diff = right_y - left_y \n",
    "    x_diff_sq = np.square(x_diff)\n",
    "    y_diff_sq = np.square(y_diff)\n",
    "    sum_sq = x_diff_sq + y_diff_sq\n",
    "    distance = np.sqrt(sum_sq)\n",
    "    data['Distance'] = distance * microns_per_pixel\n",
    "    \n",
    "    # Add Deflection Column to DF\n",
    "    # Note: deflection refers to the total pillar deflection\n",
    "    deflection = unloaded_distance - (distance * microns_per_pixel)\n",
    "    data['Deflection'] = deflection\n",
    "\n",
    "    # Plot Deflection\n",
    "    fig, ax1 = plt.subplots(1, figsize=(20, 10))\n",
    "    fig.suptitle(current_tissue)\n",
    "    ax1.plot(data['Time'], data['Deflection'])\n",
    "    ax1.set_ylabel(\"Deflection (Microns)\")\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    \n",
    "    # Select Spontaneous Beating Region\n",
    "    sp_start = regimen.loc[regimen['Region'] == \"Spontaneous\", 'First Frame'][0]\n",
    "    sp_stop = regimen.loc[regimen['Region'] == \"Spontaneous\", 'Last Frame'][0]\n",
    "    spontaneous = data.iloc[sp_start:sp_stop]\n",
    "    x = spontaneous.loc[:,'Deflection']\n",
    "\n",
    "    # Determine Baseline Correction Based on Minima for Each Second in Spontaneous Region\n",
    "    seconds = np.arange(sp_start, sp_stop, frame_rate)\n",
    "    num = len(seconds)\n",
    "    mins_deflection = np.zeros(num)\n",
    "    idxs = np.zeros(num)\n",
    "    maxs_distance = np.zeros(num)\n",
    "    for i, x in enumerate(seconds):\n",
    "        min_val = spontaneous.loc[x:(x+frame_rate)].loc[:,'Deflection'].min()\n",
    "        min_index = spontaneous.loc[x:(x+frame_rate)].loc[:,'Deflection'].idxmin()\n",
    "        max_distance = spontaneous.loc[x:(x+frame_rate)].loc[:,'Distance'].max()\n",
    "        mins_deflection[i] = min_val\n",
    "        idxs[i] = min_index\n",
    "        maxs_distance[i] = max_distance\n",
    "\n",
    "    baseline_deflection_avg = np.mean(mins_deflection)\n",
    "    baseline_distance_avg = np.mean(maxs_distance)\n",
    "\n",
    "    # Calculate Active Deflection Based on Baseline\n",
    "    active_deflection = data.loc[:,'Deflection'] - baseline_deflection_avg\n",
    "    data['Active Deflection'] = active_deflection\n",
    "\n",
    "    # Reformat Tissue Name\n",
    "    current_tissue = current_tissue.replace('.', '')\n",
    "\n",
    "    # Calculate Force and Stress\n",
    "    data['Active Force (uN)'] = active_deflection * coefficient \n",
    "    data['Force (uN)'] = deflection * coefficient\n",
    "    area = widths[widths['Tissue'] == current_tissue]['Area (mm2)']\n",
    "    area = area.to_numpy()[0]\n",
    "    width = widths[widths['Tissue'] == current_tissue]['Width (um)']\n",
    "    width = width.to_numpy()[0]\n",
    "    data['Stress (mN/mm2)'] = ((data['Force (uN)'])/1000) / area\n",
    "    data['Active Stress (mN/mm2)'] = (data['Active Force (uN)']/1000) / area\n",
    "    \n",
    "\n",
    "    # Define Passive Tension and Length\n",
    "    passive_tension = baseline_deflection_avg * coefficient\n",
    "    passive_stress = passive_tension / area\n",
    "    passive_length = baseline_distance_avg\n",
    "\n",
    "    # Calculate Velocity and Add to Data\n",
    "    velocity = (pd.Series(data=deflection).diff())/(1/frame_rate)\n",
    "    data['Velocity'] = velocity\n",
    "\n",
    "    # Differentiate Contraction and Relaxation Velocity \n",
    "    data['Contraction Velocity'] = velocity\n",
    "    data.loc[(data['Contraction Velocity']<0),'Contraction Velocity']=0\n",
    "\n",
    "    data['Relaxation Velocity'] = velocity \n",
    "    data.loc[(data['Relaxation Velocity']>0),'Relaxation Velocity']=0\n",
    "    data['Relaxation Velocity'] = abs(data['Relaxation Velocity'])\n",
    "\n",
    "    # Replace all NaNs with 0 \n",
    "    data = data.fillna(0)\n",
    "\n",
    "    # Calculate Max Values \n",
    "    max_contraction_velocity = max(data['Contraction Velocity'])\n",
    "    max_relaxation_velocity = max(data['Relaxation Velocity'])\n",
    "    max_force = max(data['Force (uN)'])\n",
    "    max_active_force = max(data['Active Force (uN)'])\n",
    "    max_stress = max(data['Stress (mN/mm2)'])\n",
    "    max_active_stress = max(data['Active Stress (mN/mm2)'])\n",
    "\n",
    "    # Create Dict for Results \n",
    "\n",
    "    results = { 'Tissue':[current_tissue], \n",
    "                'Passive Tension (uN)':[passive_tension], \n",
    "                'Passive Stress (uN/mm2)': [passive_stress], \n",
    "                'Passive Length (um)':[passive_length], \n",
    "                'Max Contraction Velocity (um/s)':[max_contraction_velocity], \n",
    "                'Max Relaxation Velocity (um/s)':[max_relaxation_velocity], \n",
    "                'Max Force (uN)':[max_force], \n",
    "                'Max Active Force (uN)':[max_active_force], \n",
    "                'Max Stress (mN/mm2)':[max_stress], \n",
    "                'Max Active Stress (mN/mm2)':[max_active_stress], \n",
    "                'Width':[width], \n",
    "                'XC Area':[area]}\n",
    "\n",
    "    return data, results, fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:01:40.781155Z",
     "start_time": "2021-08-18T20:01:40.766132Z"
    }
   },
   "outputs": [],
   "source": [
    "def region_contractility(data, tissue, start, stop, set_freq, region_name):\n",
    "    \n",
    "    # Select and Plot Trace Region\n",
    "    region = data.iloc[start:stop]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(20, 10))\n",
    "    fig.suptitle('Tissue {} {} Region'.format(tissue, region_name))\n",
    "    ax1.plot(region['Time'], region['Active Force (uN)'])\n",
    "    ax1.set_ylabel(\"Active Force (uN)\")\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # Find Range of Signal in Region \n",
    "    max_region = max(region.loc[:,'Active Force (uN)'])\n",
    "    min_region = min(region.loc[:,'Active Force (uN)'])\n",
    "    range_region = max_region - min_region\n",
    "\n",
    "    # Find Max Force and Stress\n",
    "    max_force = max(region['Force (uN)']) \n",
    "    max_active_force = max(region['Active Force (uN)'])\n",
    "    max_stress = max(region['Stress (mN/mm2)'])\n",
    "    max_active_stress = max(region['Active Stress (mN/mm2)'])\n",
    "\n",
    "    # Change set_freq for regions without stimulation \n",
    "    if set_freq == 0: \n",
    "        set_freq = 2\n",
    "    else: \n",
    "        set_freq = set_freq\n",
    "\n",
    "    # Find Peaks in Region \n",
    "    x = region['Active Force (uN)']\n",
    "    peaks, properties = scipy.signal.find_peaks(x, distance= ((1/set_freq) * frame_rate)*0.9, height=0, prominence = (range_region/4))\n",
    "\n",
    "    # Create DataFrame to Store Contraction Peak Info\n",
    "    peak_info = pd.DataFrame(properties)\n",
    "    peak_info.insert(0, \"Location\", peaks)\n",
    "\n",
    "    # Exclude Peaks That Overlap Ends of Video\n",
    "    min_cutoff = int(frame_rate)\n",
    "    max_cutoff = len(data) - int(frame_rate)\n",
    "    peak_info = peak_info.drop(peak_info[(peak_info['Location'] < min_cutoff) | (peak_info['Location'] >max_cutoff)].index.to_list(), axis=0)\n",
    "    peaks = np.array(peak_info['Location'])\n",
    "    num_peaks = len(peaks)\n",
    "    \n",
    "    fw90m_left = scipy.signal.peak_widths(x, peaks, rel_height=0.9)[2] * (1/frame_rate)\n",
    "    fw90m_right = scipy.signal.peak_widths(x, peaks, rel_height=0.9)[3] * (1/frame_rate)\n",
    "\n",
    "    left_bases = np.around(scipy.signal.peak_widths(x, peaks, rel_height=0.9)[2])\n",
    "    right_bases = np.around(scipy.signal.peak_widths(x, peaks, rel_height=0.9)[3])\n",
    "    \n",
    "    # Plot Region Trace with Overlaid Peaks \n",
    "    ax1.plot((peaks + start)/frame_rate, x[peaks + start], \"X\")\n",
    "    ax1.vlines(x=(peaks + start)/frame_rate, ymin=x[peaks + start] - np.array(peak_info['prominences']), ymax = x[peaks + start])\n",
    "    ax1.hlines(y=x[peaks + start] - (0.9 * np.array(peak_info['prominences'])), xmin=(fw90m_left + (start/frame_rate)), xmax=(fw90m_right + (start/frame_rate)))\n",
    "\n",
    "\n",
    "    # Determine the Force and Stress of Each Peak in the Region\n",
    "    peak_info['Active Force'] = (x[peaks + start]).to_list()\n",
    "    x_force = region['Force (uN)']\n",
    "    peak_info['Force'] = x_force[peaks + start].to_list()\n",
    "    x_stress = region['Stress (mN/mm2)']\n",
    "    peak_info['Stress'] = x_stress[peaks + start].to_list()\n",
    "    x_active_stress = region['Active Stress (mN/mm2)']\n",
    "    peak_info['Active Stress'] = x_active_stress[peaks + start].to_list()\n",
    "\n",
    "    # Repeat Peak Finding for Velocity\n",
    "\n",
    "    # Plot Contraction Velocity\n",
    "    ax2.plot(region['Time'], region['Velocity'])\n",
    "    ax2.set_ylabel(\"Velocity (Microns/S)\")\n",
    "    ax2.set_xlabel(\"Time (s)\")\n",
    "\n",
    "    # Find Range of Velocity in Region \n",
    "    max_contraction_velocity = max(region.loc[:,'Contraction Velocity'])\n",
    "    min_contraction_velocity = min(region.loc[:,'Contraction Velocity'])\n",
    "    range_region = max_contraction_velocity - min_contraction_velocity\n",
    "\n",
    "    # Select Velocity Based on Max Velocity During Contract 90\n",
    "    con_vel_peaks = [] \n",
    "    for i, p in enumerate(peaks):\n",
    "        vel = np.array(region['Contraction Velocity'][int(left_bases[i]):(p+1)])\n",
    "        vel_peak = np.argmax(vel) + int(left_bases[i]) \n",
    "        con_vel_peaks.append(vel_peak)\n",
    "\n",
    "    con_vel_peaks = np.array(con_vel_peaks)\n",
    "    \n",
    "    # Plot Region Trace with Overlaid Peaks \n",
    "    \n",
    "    ax2.plot((con_vel_peaks + start)/frame_rate, region['Contraction Velocity'][start + con_vel_peaks], \"X\")\n",
    "\n",
    "    # Add Contraction Velocity Peaks to Peak Info DF\n",
    "    peak_info['Contraction Velocity'] = region['Contraction Velocity'][start + con_vel_peaks].to_list()\n",
    "\n",
    "    #Relaxation Velocity\n",
    "\n",
    "    # Find Range of Relaxation Velocity in Region \n",
    "    max_relaxation_velocity = max(region.loc[:,'Relaxation Velocity'])\n",
    "    min_relaxation_velocity = min(region.loc[:,'Relaxation Velocity'])\n",
    "    range_region = max_relaxation_velocity - min_relaxation_velocity\n",
    "\n",
    "    # Select Velocity Based on Max Velocity During Contract 90\n",
    "    relax_vel_peaks = [] \n",
    "    for i, p in enumerate(peaks):\n",
    "        vel = np.array(region['Relaxation Velocity'][p:(1 + int(right_bases[i]))])\n",
    "        vel_peak = np.argmax(vel) + p\n",
    "        relax_vel_peaks.append(vel_peak)\n",
    "\n",
    "    relax_vel_peaks = np.array(relax_vel_peaks)\n",
    "    \n",
    "    # Plot Region Trace with Overlaid Peaks \n",
    "    ax2.plot((relax_vel_peaks + start)/frame_rate, -1 *(region['Relaxation Velocity'][start + relax_vel_peaks]), \"X\")\n",
    "\n",
    "    # Add Relaxation Velocity Peaks to Peak Info DF\n",
    "    peak_info['Relaxation Velocity'] = region['Relaxation Velocity'][start + relax_vel_peaks].to_list()\n",
    "\n",
    "    # Determine Region Beat Frequency\n",
    "    front = peaks[1:num_peaks]\n",
    "    back = peaks[0:(num_peaks-1)]\n",
    "    periods = front - back \n",
    "    periods = periods / frame_rate\n",
    "    delta_periods = periods[1:len(periods)] - periods[0:(len(periods) - 1)]\n",
    "\n",
    "    # Remove Outlier from RR Intervals to Correct Calculated Frequency\n",
    "    periods = pd.Series(periods)\n",
    "    stat = cb.boxplot_stats(periods)\n",
    "    periods = periods.replace(stat[0]['fliers'], np.nan)\n",
    "    freqs = np.reciprocal(periods)\n",
    "    freq = np.mean(freqs)\n",
    "\n",
    "    # Characterize Beat Variability\n",
    "    rr_interval = np.mean(periods)\n",
    "    sdrr = np.std(periods)\n",
    "    rmssd = np.sqrt(np.mean(delta_periods))\n",
    "    \n",
    "    # Determine Max Frequency in Region \n",
    "    if len(freqs) > 0:\n",
    "        max_freq = freqs.max()\n",
    "    else: \n",
    "        max_freq = 0\n",
    "\n",
    "    # Remove Outliers from Peak Metrics \n",
    "    metrics = ['Force', 'Active Force', 'Stress', 'Active Stress', 'Contraction Velocity', 'Relaxation Velocity']\n",
    "    no_out = pd.DataFrame()\n",
    "    for i in metrics: \n",
    "        stat = cb.boxplot_stats(peak_info[peak_info[i].notna()][i])\n",
    "        print('Tissue {} {} Region {} Outliers: {}'.format(tissue, region_name, i, stat[0]['fliers']))\n",
    "        new_variable = peak_info[i].replace(stat[0]['fliers'], np.nan)\n",
    "        no_out[i] = new_variable\n",
    "\n",
    "    print('')\n",
    "    print('**************************************')\n",
    "    print('')\n",
    "\n",
    "    # Calculate Averages After Outlier Removal\n",
    "    mean_force = np.mean(no_out['Force'])\n",
    "    mean_stress = np.mean(no_out['Stress'])\n",
    "    mean_active_force = np.mean(no_out['Active Force'])\n",
    "    mean_active_stress = np.mean(no_out['Active Stress'])\n",
    "    mean_contraction_velocity = np.mean(no_out['Contraction Velocity'])\n",
    "    mean_relaxation_velocity = np.mean(no_out['Relaxation Velocity'])\n",
    "\n",
    "    # Create Dictionary of Results\n",
    "\n",
    "    results = { 'Tissue':[tissue], \n",
    "                'Frequency': [freq], \n",
    "                'Max Frequency': [max_freq], \n",
    "                'Mean Force': [mean_force], \n",
    "                'Max Force': [max_force],\n",
    "                'Mean Stress': [mean_stress], \n",
    "                'Max Stress': [max_stress], \n",
    "                'Mean Active Force': [mean_active_force], \n",
    "                'Max Active Force': [max_active_force], \n",
    "                'Mean Active Stress': [mean_active_stress], \n",
    "                'Max Active Stress': [max_active_stress], \n",
    "                'Mean Contraction Velocity':[mean_contraction_velocity],\n",
    "                'Max Contraction Velocity':[max_contraction_velocity], \n",
    "                'Mean Relaxation Velocity' : [mean_relaxation_velocity], \n",
    "                'Max Relaxation Velocity':[max_relaxation_velocity],\n",
    "                'RR Interval':[rr_interval], \n",
    "                'SDRR':[sdrr], \n",
    "                'RMSSD':[rmssd] }\n",
    "    \n",
    "    # Returns the Results Dict\n",
    "    return results, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:02:10.265116Z",
     "start_time": "2021-08-18T20:01:40.782154Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "region_names = [] \n",
    "count = 0     \n",
    "\n",
    "with matplotlib.backends.backend_pdf.PdfPages(main_folder + 'Compiled Traces.pdf') as pdf: \n",
    "    for x in correct_csv:    \n",
    "        tissue = x \n",
    "        data, results, fig = load_trace(tissue)\n",
    "\n",
    "        # Save Figure to PDF\n",
    "        pdf.savefig(fig)\n",
    "\n",
    "        if count==0:\n",
    "            results_overall = pd.DataFrame(results);\n",
    "        else: \n",
    "            results_to_add = pd.DataFrame(results)\n",
    "            results_overall = pd.concat([results_overall, results_to_add]);\n",
    "        \n",
    "        del results\n",
    "\n",
    "        for i, row in regimen.iterrows():\n",
    "            start = int(row['First Frame'])\n",
    "            stop = int(row['Last Frame'])\n",
    "            set_freq = row['Freq (Hz)']\n",
    "            region_name = (str(row['Region']) + \" \" + str(set_freq) +  \" Hz\")\n",
    "\n",
    "            results, fig = region_contractility(data, tissue, start, stop, set_freq, region_name)\n",
    "\n",
    "            # Save Figure to PDF\n",
    "            pdf.savefig(fig)\n",
    "            \n",
    "            region_results = pd.DataFrame(results)\n",
    "\n",
    "            if count == 0: \n",
    "                results_dict[region_name] = region_results\n",
    "                region_names.append(region_name)\n",
    "            else: \n",
    "                results_dict[region_name] = pd.concat([results_dict[region_name], region_results])\n",
    "\n",
    "        # Change count flag     \n",
    "        count = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T20:02:10.441078Z",
     "start_time": "2021-08-18T20:02:10.266117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save results to Excel sheet\n",
    "xlsx_file = os.path.join(main_folder, \"Analysis.xlsx\")\n",
    "writer = ExcelWriter(xlsx_file)\n",
    "\n",
    "# Save 'Overall' results to excel \n",
    "results_overall.to_excel(writer, sheet_name = 'Overall')\n",
    "\n",
    "# Cycle through results for each region \n",
    "print(region_names)\n",
    "for x in region_names:\n",
    "    results_dict[x].to_excel(writer, sheet_name = x)\n",
    "    \n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "106adc3d94f175c902e9a72c4ea6d103ecf512e437ffa51ee7b3d844a7094657"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
